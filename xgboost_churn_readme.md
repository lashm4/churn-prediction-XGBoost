# ğŸ¦ Customer Churn Prediction (XGBoost)

## ğŸ“Œ Project Overview

This project predicts **customer churn** (whether a customer leaves the bank) using **XGBoost**.  
The model is trained on customer demographic and financial data and outputs churn risk.

### ğŸ”‘ Key Steps:
1. Data Cleaning & Preprocessing  
2. Exploratory Data Analysis (EDA + Visuals)  
3. Feature Engineering  
4. Model Training & Evaluation  
5. Interpretation of Results  
6. Saving Model for Deployment  

---

## ğŸ“Š Dataset

- **Source:** [Bank Customer Churn Dataset (Kaggle)](https://www.kaggle.com/datasets/shubhammeshram579/bank-customer-churn-prediction)  
- **Target:** `Exited` â†’ (1 = Churned, 0 = Stayed)  
- **Features:** Demographics, account information, and financial data.  

---

## âš™ï¸ Installation

Clone this repository and install dependencies:

```bash
git clone https://github.com/lashm4/Bank-Churn-Prediction.git
cd Bank-Churn-Prediction
pip install -r requirements.txt
```

---

## ğŸš€ Usage

Run the Jupyter Notebook:

```bash
jupyter notebook notebooks/xgboost_churn_model.ipynb
```

Or load the pre-trained model for predictions:

```python
import joblib
import pandas as pd

# Load XGBoost model
xgb_model = joblib.load("models/xgboost_churn_model.pkl")

# Example usage
X_new = pd.DataFrame([[600, 40, 3, 60000]],
                     columns=["CreditScore","Age","NumOfProducts","EstimatedSalary"])
xgb_pred = xgb_model.predict(X_new)
print("XGBoost Churn Prediction:", xgb_pred)
```

---

## ğŸ“ˆ Model Performance

- **Test Accuracy:** 86.8%  
- **ROC-AUC:** 0.728 â†’ good separation of churners  
- **Confusion Matrix:** [[1535, 58], [207, 201]]  
- **Classification Report:**
  - Class 0 (Non-churners): Precision = 0.88, Recall = 0.96, F1-score = 0.92  
  - Class 1 (Churners): Precision = 0.78, Recall = 0.49, F1-score = 0.60  

---

## ğŸ”‘ Key Features & Insights

Top features contributing to churn (XGBoost Feature Importance):
- NumOfProducts â†’ 28.0%  
- Age â†’ 17.2%  
- IsActiveMember â†’ 16.5%  
- Geography_Germany â†’ 11.4%  
- Gender â†’ 6.1%  
- Balance â†’ 6.0%  
- Geography_Spain â†’ 4.3%  

Insights:
- Customers with fewer products, older age, and inactive status are more likely to churn.
- German customers have a higher risk of churn.

---

## ğŸ“Œ Next Steps

- Compare XGBoost with Logistic Regression and other models (Random Forest, Gradient Boosting)
- Tune hyperparameters for better performance
- Deploy model via Streamlit or Flask for real-time predictions
- Monitor model performance on new data

---

## ğŸ“œ Requirements

Dependencies are listed in `requirements.txt`, including:
- pandas  
- numpy  
- scikit-learn  
- xgboost  
- seaborn  
- matplotlib  
- joblib  
- jupyter  

---

## ğŸ‘©â€ğŸ’» Author

Created by **Lashmi M.** â€“ feel free to reach out!

